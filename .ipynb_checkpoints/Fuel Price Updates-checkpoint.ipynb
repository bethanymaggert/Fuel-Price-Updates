{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089f61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy.types\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import os \n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1f9b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US Inserted Row Count: 0\n",
      "Canada Inserted Row Count: 0\n"
     ]
    }
   ],
   "source": [
    "#US\n",
    "\n",
    "# Find date 2 months ago so it can go into the api\n",
    "two_months_ago = datetime.now() - timedelta(days=60)\n",
    "\n",
    "# Format the as string date format\n",
    "start_date = two_months_ago.strftime('%Y-%m-%d')\n",
    "\n",
    "# Grab the api from the EIA website\n",
    "api_url = f'https://api.eia.gov/v2/petroleum/pri/gnd/data/?frequency=weekly&data[0]=value&facets[product][]=EPD2D&facets[product][]=EPMM&facets[product][]=EPMP&facets[product][]=EPMR&facets[series][]=EMD_EPD2D_PTE_NUS_DPG&facets[series][]=EMM_EPMM_PTE_NUS_DPG&facets[series][]=EMM_EPMP_PTE_NUS_DPG&facets[series][]=EMM_EPMR_PTE_NUS_DPG&start={start_date}&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000'\n",
    "api_key = 'TpnzzxiOIeII7cZuWB2dagJpu9YLNF2WMDqEofb2'\n",
    "\n",
    "params = {\n",
    "    'api_key': api_key\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(api_url,params=params)\n",
    "# This will raise an HTTPError if the response was not successful\n",
    "    response.raise_for_status()  \n",
    "\n",
    "# Get the JSON data and put it in a dataframe\n",
    "    jsonData = response.json()\n",
    "    df = pd.json_normalize(jsonData, record_path=['response','data'])\n",
    "    df[['period','series','series-description','value']]\n",
    "\n",
    "# Changing Column names from api to match sql output table\n",
    "    column_mapping = {\n",
    "        'period': 'PublishDate',   \n",
    "        'series': 'SeriesId',\n",
    "        'series-description': 'Description',\n",
    "        'value': 'Price'\n",
    "\n",
    "    }\n",
    "\n",
    "    df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Remove dollars per gallon to match 'description' in Sql\n",
    "    df['Description'] = df['Description'].str.replace(r\" \\(.+?\\)$\", \"\", regex=True)\n",
    "\n",
    "# Adding Columns to match sql output table\n",
    "    df['Country'] = 'USA'\n",
    "    df['Frequency'] = 'W'\n",
    "    df['UnitofMeasure'] = 'Dollars per Gallon'\n",
    "    df['Source'] = 'EIA, U.S. Energy Information Administration'\n",
    "    \n",
    "# Creating 'Grade' Column but adding 'weekly' to the end to mathc sql output table\n",
    "    df['Grade'] = df['Description'].copy()\n",
    "    df['Grade'] = df['Grade'] + ',Weekly'\n",
    "\n",
    "# Get the current date for 'CreatedOn' and 'UpdatedOn' column\n",
    "    process_date = datetime.now()\n",
    "\n",
    "# Adding other columns that are not hardcoded\n",
    "    df['PublishDate'] = pd.to_datetime(df['PublishDate'])\n",
    "    df['CreatedOn'] = process_date\n",
    "    df['UpdatedOn'] = process_date\n",
    "\n",
    "# Sort by PublishDate to Rank\n",
    "    df_sorted = df.sort_values(by='PublishDate', ascending=False)\n",
    "\n",
    "# Use Dense so newest publish date will be 1\n",
    "    df['Id'] = df_sorted['PublishDate'].rank(method='dense', ascending=False).astype(int)\n",
    "\n",
    "# errors caused by requests\n",
    "except requests.exceptions.ConnectionError as conn_err:\n",
    "    print(f'Error Connecting: {conn_err}') \n",
    "except requests.exceptions.Timeout as timeout_err:\n",
    "    print(f'Timeout Error: {timeout_err}')   \n",
    "except requests.exceptions.RequestException as req_err:\n",
    "    print(f'Error: {req_err}')\n",
    "#error that is not caused by requests\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')\n",
    "# Connect to Sql Server\n",
    "server = 'mssql-dev-01'\n",
    "database = 'Reporting'\n",
    "username = 'EditorialWrite'\n",
    "password = 'BBWrite01.'\n",
    "driver = 'ODBC Driver 17 for SQL Server'\n",
    "\n",
    "\n",
    "conn_str = f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver}'\n",
    "engine = sqlalchemy.create_engine(conn_str)\n",
    "\n",
    "# Write data frame to sql\n",
    "df.to_sql('core_staging', schema='fuel', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Merge so 'Updated' column will update and output # rows inserted in Fuel_core table\n",
    "merge_statement = text(\"\"\"\n",
    "IF OBJECT_ID('tempdb..##MergeOutput') IS NOT NULL DROP TABLE ##MergeOutput;\n",
    "CREATE TABLE ##MergeOutput (\n",
    "    Action VARCHAR(10)\n",
    ");\n",
    "\n",
    "MERGE INTO  Reporting.fuel.Core AS target\n",
    "USING (SELECT PublishDate, Country,Grade,Frequency,Id, Price, CreatedOn, UpdatedOn,UnitofMeasure,Description,Source,SeriesId FROM Reporting.fuel.core_staging) AS source\n",
    "ON (target.[PublishDate]=source.[PublishDate]\n",
    "    AND target.[Country]=source.[Country]\n",
    "    AND target.[SeriesId]=source.[SeriesId]\n",
    "    AND target.[Frequency]=source.[Frequency])\n",
    "WHEN MATCHED AND target.Price != source.Price THEN \n",
    "    UPDATE SET Price = source.Price,\n",
    "        UpdatedOn = source.UpdatedOn,\n",
    "        UnitOfMeasure= source.UnitOfMeasure,\n",
    "        Grade =source.Grade,\n",
    "        Description=source.Description,\n",
    "        Source=source.Source\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (PublishDate, Country,Grade,Frequency,Id, Price, CreatedOn, \n",
    "        UpdatedOn,UnitofMeasure,Description,Source,SeriesId)\n",
    "VALUES (source.PublishDate, source.Country,source.Grade,source.Frequency,source.Id, source.Price, source.CreatedOn,\n",
    "        source.UpdatedOn,source.UnitofMeasure,source.Description,source.Source,source.SeriesId)\n",
    "OUTPUT $action INTO ##MergeOutput;\n",
    "\"\"\")\n",
    "\n",
    "count_query = text(\"SELECT COUNT(*) AS InsertedCount FROM ##MergeOutput WHERE Action = 'INSERT';\")\n",
    "\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(merge_statement)\n",
    "    inserted_count_result = conn.execute(count_query).scalar()\n",
    "    \n",
    "#Drop the global temp table\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS ##MergeOutput;\"))\n",
    "\n",
    "print(f\"US Inserted Row Count: {inserted_count_result}\")\n",
    "\n",
    "# Canada\n",
    "\n",
    "base_url = 'https://www2.nrcan.gc.ca/eneene/sources/pripri/prices_byyear_e.cfm?productID='\n",
    "\n",
    "# Dictionary mapping fuel types to their product IDs.\n",
    "CanFuelPrices = {'Regular':1, 'Mid-Grade':2, 'Premium':3, 'Diesel':5}\n",
    "\n",
    "# Create a list to store data for all fuel types.\n",
    "all_fuel_data = []\n",
    "\n",
    "# Iterate over the dictionary items.\n",
    "for fuel_type, prod_id in CanFuelPrices.items():\n",
    "    full_url = f\"{base_url}{prod_id}\"\n",
    "    response = requests.get(full_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', id='pricesTable')\n",
    "        if table:\n",
    "            # Process each table row\n",
    "            for row in table.find_all('tr')[1:]:  # Skip header row\n",
    "                cells = row.find_all('td')\n",
    "                if cells:\n",
    "                    # Parse date and filter rows.\n",
    "                    date_str = cells[0].get_text(strip=True)\n",
    "                    try:\n",
    "                        date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        # Skip rows with invalid date format.\n",
    "                        continue\n",
    "                    \n",
    "                    if date >= two_months_ago:\n",
    "                        # Assuming the second cell contains the price.\n",
    "                        price = cells[1].get_text(strip=True)\n",
    "                        # Append to the list as a dictionary.\n",
    "                        all_fuel_data.append({\n",
    "                            'Fuel Type': fuel_type,\n",
    "                            'Date': date_str,\n",
    "                            'Price': price\n",
    "                            # Add other data columns as needed.\n",
    "                        })\n",
    "        else:\n",
    "            print(f\"No table with id 'pricesTable' found for {fuel_type}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve {fuel_type} data, status code: {response.status_code}\")\n",
    "\n",
    "        \n",
    "# Changing Column names from url to match sql output table\n",
    "grade_mapping = {\n",
    "    'Regular': 'Gasoline',\n",
    "    'Mid-Grade': 'Gasoline, Mid-Grade',\n",
    "    'Premium': 'Gasoline, Premium',\n",
    "    'Diesel': 'Diesel'\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the gathered data.\n",
    "df = pd.DataFrame(all_fuel_data)\n",
    "\n",
    "# Divide the 'Price' column by 100 and map grade\n",
    "df['Price'] = df['Price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "df['Price'] = df['Price'] / 100\n",
    "df['Grade'] = df['Fuel Type'].map(grade_mapping)\n",
    "\n",
    "\n",
    "# Updating the DataFrame's column names to match SQL table's column names\n",
    "column_mapping = {\n",
    "    'Date': 'PublishDate'\n",
    "}\n",
    "\n",
    "df.rename(columns=column_mapping, inplace=True)  \n",
    "df.drop(columns='Fuel Type', inplace=True)\n",
    "\n",
    "# Adding Columns to match sql output table\n",
    "df['Country'] = 'CAN'\n",
    "df['Frequency'] = 'W'\n",
    "df['UnitofMeasure'] = 'CAD per litre'\n",
    "df['Source'] = ''\n",
    "df['Description']= ''\n",
    "\n",
    "# Creating SeriesID column by dupliating 'grade' and making slight adjustments\n",
    "df['SeriesId'] = df['Grade'].copy()\n",
    "df['SeriesId'] = 'Canada.' + df['Grade'] + '.Weekly'\n",
    "\n",
    "def create_series_id(grade):\n",
    "    grade_formatted = grade.replace(', ', '.')\n",
    "    if grade == 'Gasoline':\n",
    "        return 'Canada.Gasoline.Regular.Weekly'\n",
    "    else:\n",
    "        return f'Canada.{grade_formatted}.Weekly'\n",
    "\n",
    "# Apply this function to each row in the 'Grade' column to create the 'SeriesId' column\n",
    "df['SeriesId'] = df['Grade'].apply(create_series_id)\n",
    "\n",
    "\n",
    "\n",
    "# Adding other columns that cannot be hardcoded\n",
    "df['PublishDate'] = pd.to_datetime(df['PublishDate'])\n",
    "df['CreatedOn'] = process_date\n",
    "df['UpdatedOn'] = process_date\n",
    "\n",
    "# Sort by PublishDate for 'Id' column\n",
    "df_sorted = df.sort_values(by='PublishDate', ascending=False)\n",
    "\n",
    "# Use Dense so newest publish date will be 1\n",
    "df['Id'] = df_sorted['PublishDate'].rank(method='dense', ascending=False).astype(int)\n",
    "    \n",
    "# Connect to Sql Server\n",
    "server = 'mssql-dev-01'\n",
    "database = 'Reporting'\n",
    "username = 'EditorialWrite'\n",
    "password = 'BBWrite01.'\n",
    "driver = 'ODBC Driver 17 for SQL Server'\n",
    "\n",
    "\n",
    "conn_str = f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver}'\n",
    "engine = sqlalchemy.create_engine(conn_str)\n",
    "\n",
    "# Write data frame to sql\n",
    "df.to_sql('core_staging', schema='fuel', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Merge so 'Updated' column will update and output # rows inserted in Fuel_core table\n",
    "merge_statement =text( \"\"\"\n",
    "DROP TABLE IF EXISTS ##MergeOutput;\n",
    "CREATE TABLE ##MergeOutput (\n",
    "    Action VARCHAR(10)\n",
    ");\n",
    "\n",
    "MERGE INTO  Reporting.fuel.Core AS target\n",
    "USING (SELECT PublishDate, Country,Grade,Frequency,Id, Price, CreatedOn, UpdatedOn,UnitofMeasure,Description,Source,SeriesId FROM Reporting.fuel.core_staging) AS source\n",
    "ON (target.[PublishDate]=source.[PublishDate]\n",
    "    AND target.[Country]=source.[Country]\n",
    "    AND target.[SeriesId]=source.[SeriesId]\n",
    "    AND target.[Frequency]=source.[Frequency])\n",
    "WHEN MATCHED AND target.Price != source.Price THEN \n",
    "    UPDATE SET Price = source.Price,\n",
    "        UpdatedOn = source.UpdatedOn,\n",
    "        UnitOfMeasure= source.UnitOfMeasure,\n",
    "        Grade =source.Grade,\n",
    "        Description=source.Description,\n",
    "        Source=source.Source\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (PublishDate, Country,Grade,Frequency,Id, Price, CreatedOn, \n",
    "        UpdatedOn,UnitofMeasure,Description,Source,SeriesId)\n",
    "VALUES (source.PublishDate, source.Country,source.Grade,source.Frequency,source.Id, source.Price, source.CreatedOn,\n",
    "        source.UpdatedOn,source.UnitofMeasure,source.Description,source.Source,source.SeriesId)\n",
    "OUTPUT $action INTO ##MergeOutput;\n",
    "\"\"\")\n",
    "\n",
    "count_query = text(\"SELECT COUNT(*) AS InsertedCount FROM ##MergeOutput WHERE Action = 'INSERT';\")\n",
    "\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(merge_statement)\n",
    "    inserted_count_result = conn.execute(count_query).scalar()\n",
    "    \n",
    "# Drop the global temp table\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS ##MergeOutput;\"))\n",
    "\n",
    "print(f\"Canada Inserted Row Count: {inserted_count_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6f46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
